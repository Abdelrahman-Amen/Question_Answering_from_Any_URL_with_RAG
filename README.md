# ğŸš€ Question-Answering from Any URL with RAG and LangChain ğŸŒ

Welcome to the Question-Answering from Any URL project! This repository showcases a cutting-edge implementation of Retrieval-Augmented Generation (RAG) combined with the power of LangChain and Google Generative AI for seamless question-answering. ğŸ§ âœ¨


![Image](https://github.com/user-attachments/assets/89de9f8e-9531-422a-a2cd-dac14eed3d98)

# ğŸ” What is RAG (Retrieval-Augmented Generation)?
Retrieval-Augmented Generation is an advanced AI framework that combines retrieval-based systems with generative models. Instead of relying solely on pre-trained knowledge, RAG enhances the model's capability by retrieving contextually relevant information from external sources like documents or web pages. This enables the generation of accurate, up-to-date, and context-aware answers. ğŸ’¡

### How it works in this project:

1. Retrieve: Content is extracted from the provided URL.

2. Embed: The content is processed into vector representations using Google Generative AI embeddings.

3. Generate: The user's question is matched with the most relevant content, and the best answer is presented.


# What I Built in This Project ğŸ› ï¸ 

This project is a web-based application where users can:

1. Input a URL: Provide the URL of any publicly accessible web page.

2. Ask a Question: Enter a question related to the content of the web page.

3. Receive an Answer: Get the most relevant answer, retrieved from the content and matched with the user's query.

# Core Features ğŸ”—

â€¢ LangChain Framework: Used to streamline the integration of loaders, splitters, embeddings, and vector stores.

â€¢ Google Generative AI: Leverages the powerful embedding-001 model for creating embeddings.

â€¢ Web Content Loader: The WebBaseLoader extracts and prepares data from the given URL.

â€¢ Text Splitting: Documents are divided into manageable chunks using the RecursiveCharacterTextSplitter to ensure smooth processing.

â€¢ Vector Search with FAISS: Uses FAISS for high-speed similarity search and matching the query to the most relevant chunk of content.

â€¢ Streamlit UI: A clean and interactive user interface for a seamless experience.



# How It Works ğŸ’»


1.User Inputs:

â€¢ Enter a URL (e.g., a blog post, article, or documentation page).

â€¢ Type a question about the content of the page.

2.Processing Pipeline:

â€¢ The content is loaded using WebBaseLoader.

â€¢ It is split into smaller chunks for better analysis.

â€¢ Google Generative AI embeddings are generated for each chunk.

â€¢ A vector store is created, enabling fast similarity search.

3.Query Matching:

â€¢ The user's question is transformed into an embedding.

â€¢ The system searches the vector store for the most relevant content.

4.Results:

â€¢ The top result is displayed to the user as the answer to their question.


# Why Use This Project ğŸŒŸ?  

â€¢ Dynamic Information: Unlike static knowledge in pre-trained models, this app fetches the latest information from the web.

â€¢ Customizable: Easily extendable to support different types of embeddings, content sources, or models.

â€¢ User-Friendly: Intuitive Streamlit interface for easy interaction.

â€¢ Educational: A great resource to understand RAG, LangChain, and how to build end-to-end NLP applications.





# Demo ğŸ“½

Below is a demonstration of how the application works:

![Demo of the Application](https://github.com/Abdelrahman-Amen/Question_Answering_from_Any_URL_with_RAG/blob/main/Demo.gif)
